{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","authorship_tag":"ABX9TyNFqDKiSrBU5RjSJmLOMMMH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQ0E188NH6ci","executionInfo":{"status":"ok","timestamp":1733893836939,"user_tz":360,"elapsed":17798,"user":{"displayName":"Kronos Vocos","userId":"08102118984188024326"}},"outputId":"03f2eb26-ef2e-4f1a-f956-fcbeea6153d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","\n","os.chdir('/content/drive/MyDrive/HRP')"]},{"cell_type":"code","source":["import pandas as pd\n","from tqdm import tqdm\n","\n","csv_file = \"ecgredone_data.csv\"\n","\n","\n","total_lines = sum(1 for _ in open(csv_file)) - 1\n","\n","\n","chunks = []\n","chunksize = 1000\n","with tqdm(desc=\"Reading CSV in chunks\", total=total_lines, unit=\"lines\") as pbar:\n","    for chunk in pd.read_csv(csv_file, chunksize=chunksize):\n","        chunks.append(chunk)\n","        pbar.update(len(chunk))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UD0VZdnsH_1J","executionInfo":{"status":"ok","timestamp":1733894056689,"user_tz":360,"elapsed":214457,"user":{"displayName":"Kronos Vocos","userId":"08102118984188024326"}},"outputId":"d75826e8-62d1-451d-f5d8-9bc62523d774"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Reading CSV in chunks: 100%|██████████| 812700/812700 [02:01<00:00, 6700.36lines/s]\n"]}]},{"cell_type":"code","source":["df_main = pd.concat(chunks, ignore_index=True)"],"metadata":{"id":"acAMCk-5IGSn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_main.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mNdvRhywIJgR","executionInfo":{"status":"ok","timestamp":1733894172798,"user_tz":360,"elapsed":290,"user":{"displayName":"Kronos Vocos","userId":"08102118984188024326"}},"outputId":"c961bef7-531e-4991-c59d-084c9fe25369"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 812700 entries, 0 to 812699\n","Data columns (total 4 columns):\n"," #   Column  Non-Null Count   Dtype \n","---  ------  --------------   ----- \n"," 0   Name    812700 non-null  object\n"," 1   Key     812700 non-null  object\n"," 2   Specs   541800 non-null  object\n"," 3   Vals    812645 non-null  object\n","dtypes: object(4)\n","memory usage: 24.8+ MB\n"]}]},{"cell_type":"code","source":["def get_dataframe(disease_code):\n","  d_ids = set(df_main[df_main['Vals'] == disease_code]['Name'])\n","  print(f'There are {len(d_ids)} patients in the dataset')\n","  df_d = df_main[df_main['Name'].isin(d_ids)]\n","  return df_d"],"metadata":{"id":"nDcuBtTjIM89"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_sinus = get_dataframe('426783006')\n","df_sinus_a = get_dataframe('164889003')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ItZ5OfZIOj4","executionInfo":{"status":"ok","timestamp":1733894175966,"user_tz":360,"elapsed":335,"user":{"displayName":"Kronos Vocos","userId":"08102118984188024326"}},"outputId":"3b95d59e-0168-472b-94a4-bb2e60532c48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 5908 patients in the dataset\n","There are 422 patients in the dataset\n"]}]},{"cell_type":"code","source":["from tqdm import tqdm\n","import numpy as np\n","\n","def create_formatted(df, disease=0, lead_target=0):\n","    \"\"\"\n","    Preprocess the DataFrame to extract ECG leads and labels, returning PyTorch tensors.\n","\n","    Parameters:\n","    - df: Pandas DataFrame containing ECG data.\n","    - disease: Integer label for the disease (e.g., 0 for Normal, 1 for Arrhythmia).\n","    - lead_target: Integer index of the target lead to use (e.g., 0 for Lead I).\n","                   If None, use all 12 leads.\n","\n","    Returns:\n","    - examples: List of tuples (leads_ref, disease)\n","                where leads_ref is a PyTorch tensor of shape (num_leads, lead_length)\n","    \"\"\"\n","    examples = []\n","    num_leads = 12\n","    lead_length = 5000  # Adjust if your signals have a different length\n","\n","    for start_idx in tqdm(range(0, len(df), 18), desc=f\"Processing {disease} samples\"):\n","        try:\n","            leads_ref = []\n","\n","            for lead_idx in range(num_leads):\n","                # If a specific lead is targeted, skip others\n","                if lead_target is not None and lead_idx != lead_target:\n","                    continue\n","\n","                # Ensure we don't go out of bounds\n","                if start_idx + lead_idx >= len(df):\n","                    raise IndexError(f\"Missing data for lead {lead_idx} at index {start_idx}. Skipping sample.\")\n","\n","                # Parse the signal\n","                row = df.iloc[start_idx + lead_idx]\n","                vals_str = row['Vals']\n","                lead_signal = np.array([float(x.strip()) for x in vals_str.strip('[]').split(',')])\n","\n","                # Ensure the lead signal is of the correct length\n","                if lead_signal.shape[0] != lead_length:\n","                    if lead_signal.shape[0] < lead_length:\n","                        padding = lead_length - lead_signal.shape[0]\n","                        lead_signal = np.pad(lead_signal, (0, padding), 'constant')\n","                    else:\n","                        lead_signal = lead_signal[:lead_length]\n","\n","                leads_ref.append(lead_signal)\n","\n","            # Convert to a PyTorch tensor\n","            if leads_ref:  # Ensure leads_ref is not empty\n","                leads_ref = torch.tensor(np.array(leads_ref), dtype=torch.float32)  # Shape: (num_selected_leads, lead_length)\n","                label = torch.tensor(disease, dtype=torch.float32)  # Convert disease label to tensor\n","                examples.append((leads_ref, label))\n","            else:\n","                print(f\"Warning: No leads extracted for sample starting at index {start_idx}. Skipping.\")\n","\n","        except IndexError as e:\n","            print(f\"Warning: Incomplete sample at index {start_idx}. Skipping.\")\n","            continue\n","        except Exception as e:\n","            print(f\"Error processing sample at index {start_idx}: {e}\")\n","            continue\n","\n","    return examples\n"],"metadata":{"id":"BpjdEspxITew"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class FeatureNN(nn.Module):\n","    def __init__(self, input_size):\n","        super(FeatureNN, self).__init__()\n","        self.fc1 = nn.Linear(input_size, 64)\n","        self.fc2 = nn.Linear(64, 32)\n","        self.fc3 = nn.Linear(32, 1)  # Binary classification\n","        self.dropout = nn.Dropout(0.3)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n"],"metadata":{"id":"-B42xuIuIfKU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install biosppy\n","!pip install scipy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8JfN03_gLvX0","executionInfo":{"status":"ok","timestamp":1733894810188,"user_tz":360,"elapsed":3664,"user":{"displayName":"Kronos Vocos","userId":"08102118984188024326"}},"outputId":"621817e5-d300-4188-ec1e-558daf19e846"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting biosppy\n","  Downloading biosppy-2.2.2-py2.py3-none-any.whl.metadata (5.7 kB)\n","Collecting bidict (from biosppy)\n","  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from biosppy) (3.12.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from biosppy) (3.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.13.1)\n","Collecting shortuuid (from biosppy)\n","  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.16.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.4.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from biosppy) (4.10.0.84)\n","Collecting pywavelets (from biosppy)\n","  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n","Collecting mock (from biosppy)\n","  Downloading mock-5.1.0-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (4.55.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (2.9.0.post0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->biosppy) (3.5.0)\n","Downloading biosppy-2.2.2-py2.py3-none-any.whl (149 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bidict-0.23.1-py3-none-any.whl (32 kB)\n","Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n","Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n","Installing collected packages: shortuuid, pywavelets, mock, bidict, biosppy\n","Successfully installed bidict-0.23.1 biosppy-2.2.2 mock-5.1.0 pywavelets-1.8.0 shortuuid-1.0.13\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from scipy.signal import find_peaks, welch\n","from scipy.stats import skew, kurtosis\n","\n","from biosppy.signals import ecg\n","import numpy as np\n","\n","def extract_features(signal, fs=500):\n","    \"\"\"\n","    Extract ECG-specific features from a single signal.\n","    \"\"\"\n","    try:\n","        # Process the ECG signal\n","        out = ecg.ecg(signal=signal, sampling_rate=fs, show=False)\n","        r_peaks = out['rpeaks']\n","\n","        # Calculate features\n","        rr_intervals = np.diff(r_peaks) / fs  # R-R intervals\n","        heart_rate = 60 / np.mean(rr_intervals) if len(rr_intervals) > 0 else 0.0\n","\n","        energy = np.sum(signal**2)\n","\n","        st_deviation = []\n","        for r_peak in r_peaks:\n","            st_idx = int(r_peak + 0.08 * fs)\n","            if st_idx < len(signal):\n","                st_deviation.append(signal[st_idx])\n","        st_deviation_mean = np.mean(st_deviation) if st_deviation else 0.0\n","\n","        qrs_duration = np.mean(rr_intervals) if len(rr_intervals) > 0 else 0.0\n","        t_wave_amplitude = np.max(signal) - np.min(signal)\n","\n","        # Combine features into an array\n","        features = [\n","            heart_rate,\n","            np.mean(rr_intervals) if len(rr_intervals) > 0 else 0.0,\n","            energy,\n","            st_deviation_mean,\n","            qrs_duration,\n","            t_wave_amplitude,\n","        ]\n","\n","        # Debug feature dimensions\n","        for i, feature in enumerate(features):\n","            if isinstance(feature, np.ndarray):\n","                print(f\"Feature {i} is not scalar. Shape: {feature.shape}\")\n","            else:\n","                print(f\"Feature {i} is scalar: {feature}\")\n","\n","        return np.array(features)\n","\n","    except Exception as e:\n","        print(f\"Error extracting features: {e}\")\n","        return np.zeros(6)  # Return zeros on failure\n"],"metadata":{"id":"rd8j-n8qIfnM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test_(model, test_data):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in test_data:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            predictions = (torch.sigmoid(outputs) > 0.5).float()\n","            correct += (predictions == labels.unsqueeze(1)).sum().item()\n","            total += labels.size(0)\n","    accuracy = correct / total\n","    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n","    return accuracy\n"],"metadata":{"id":"OnEXo8xkIxj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["formatted_data = create_formatted(df_sinus[:18*5], disease=0, lead_target=0)\n","for i, (features, label) in enumerate(formatted_data[:5]):\n","    print(f\"Sample {i}: Feature shape: {features.shape}, Label shape: {label.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99IwpRoMMhFP","executionInfo":{"status":"ok","timestamp":1733895206321,"user_tz":360,"elapsed":71,"user":{"displayName":"Kronos Vocos","userId":"08102118984188024326"}},"outputId":"d3e48389-c1f1-4c8f-ff87-1c5c304cfb83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 5/5 [00:00<00:00, 633.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Sample 0: Feature shape: torch.Size([1, 5000]), Label shape: torch.Size([])\n","Sample 1: Feature shape: torch.Size([1, 5000]), Label shape: torch.Size([])\n","Sample 2: Feature shape: torch.Size([1, 5000]), Label shape: torch.Size([])\n","Sample 3: Feature shape: torch.Size([1, 5000]), Label shape: torch.Size([])\n","Sample 4: Feature shape: torch.Size([1, 5000]), Label shape: torch.Size([])\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["for lead_num in range(12):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    feature_dim = 8  # Number of features extracted\n","    model = FeatureNN(input_size=feature_dim).to(device)\n","\n","    criterion = nn.BCEWithLogitsLoss()  # Binary classification loss\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","    print(f\"Lead {lead_num}:\")\n","    normal = create_formatted(df_sinus.iloc[:18*300], 0, lead_num)\n","    arythmia = create_formatted(df_sinus_a.iloc[:18*300], 1, lead_num)\n","    train_data = normal + arythmia\n","    train_loader = prepare_dataloader(train_data)\n","\n","    for epoch in range(100):\n","        model.train()\n","        running_loss = 0.0\n","\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # Extract features from the raw signals\n","            inputs = extract_features_batch(inputs)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            labels = labels.unsqueeze(1)  # Ensure labels have shape [batch_size, 1]\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        if epoch % 25 == 0:\n","            print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n","    test_data = create_formatted(df_sinus.iloc[18*300:18*400], 0, lead_num) + \\\n","                create_formatted(df_sinus_a.iloc[18*300:18*400], 1, lead_num)\n","    x = test_(model, test_data)\n","    print()\n","    del model\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":964},"id":"n5f8lUQkIp9Z","executionInfo":{"status":"error","timestamp":1733894984372,"user_tz":360,"elapsed":2805,"user":{"displayName":"Kronos Vocos","userId":"08102118984188024326"}},"outputId":"6734b8bf-0469-4d9e-c31e-4f4e3ed7d020"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Lead 0:\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:00<00:00, 718.80it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:00<00:00, 712.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n","Error extracting features: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (32x6 and 8x64)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-33c965c525b9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure labels have shape [batch_size, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-27-4f999656af66>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x6 and 8x64)"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from biosppy.signals import ecg\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Feature Extraction Function\n","def extract_ecg_features(signal, fs=300):\n","    \"\"\"\n","    Extract ECG-specific features from the signal.\n","    \"\"\"\n","    try:\n","        # Process the ECG signal and extract R-peaks\n","        out = ecg.ecg(signal=signal, sampling_rate=fs, show=False)\n","        r_peaks = out['rpeaks']\n","\n","        # Calculate features\n","        rr_intervals = np.diff(r_peaks) / fs  # R-R intervals\n","        heart_rate = 60 / np.mean(rr_intervals) if len(rr_intervals) > 0 else 0.0\n","        energy = np.sum(signal**2)\n","\n","        # ST segment deviation (example calculation at 0.08s post R-peak)\n","        st_deviation = []\n","        for r_peak in r_peaks:\n","            st_idx = int(r_peak + 0.08 * fs)\n","            if st_idx < len(signal):\n","                st_deviation.append(signal[st_idx])\n","        st_deviation_mean = np.mean(st_deviation) if st_deviation else 0.0\n","\n","        # Other features\n","        qrs_duration = np.mean(rr_intervals) if len(rr_intervals) > 0 else 0.0\n","        t_wave_amplitude = np.max(signal) - np.min(signal)  # Approximation\n","\n","        # Combine features into an array\n","        features = [\n","            heart_rate,\n","            np.mean(rr_intervals) if len(rr_intervals) > 0 else 0.0,\n","            energy,\n","            st_deviation_mean,\n","            qrs_duration,\n","            t_wave_amplitude,\n","        ]\n","        return np.array(features)\n","\n","    except Exception as e:\n","        print(f\"Error extracting features: {e}\")\n","        return np.zeros(6)  # Return zeros if feature extraction fails\n","\n","# Batch Feature Extraction Function\n","def extract_features_batch(signals):\n","    \"\"\"\n","    Extract features for a batch of signals.\n","    \"\"\"\n","    features = []\n","    for signal in signals:\n","        # Convert PyTorch tensor to NumPy if necessary\n","        if isinstance(signal, torch.Tensor):\n","            signal = signal.numpy()\n","\n","        # Extract features\n","        extracted_features = extract_ecg_features(signal)\n","\n","        # Ensure the feature vector is flattened\n","        extracted_features = np.squeeze(extracted_features)\n","        features.append(extracted_features)\n","\n","    # Convert to PyTorch tensor\n","    features = torch.tensor(features, dtype=torch.float32)\n","    return features\n","\n","# Create Formatted Data Function\n","def create_formatted(df, disease=0, lead_target=0):\n","    \"\"\"\n","    Preprocess the DataFrame to extract ECG leads and labels with medical features.\n","    \"\"\"\n","    examples = []\n","    fs = 300  # Sampling frequency\n","\n","    for start_idx in tqdm(range(0, len(df), 18), desc=f\"Processing {disease} samples\"):\n","        try:\n","            leads_ref = []\n","\n","            for lead_idx in range(12):  # Loop through leads\n","                if lead_target is not None and lead_idx != lead_target:\n","                    continue\n","\n","                if start_idx + lead_idx >= len(df):\n","                    raise IndexError(f\"Missing data for lead {lead_idx} at index {start_idx}. Skipping sample.\")\n","\n","                row = df.iloc[start_idx + lead_idx]\n","                vals_str = row['Vals']\n","                lead_signal = np.array([float(x.strip()) for x in vals_str.strip('[]').split(',')])\n","                lead_signal = np.nan_to_num(lead_signal)  # Clean invalid values\n","\n","                # Extract features\n","                features = extract_ecg_features(lead_signal, fs=fs)\n","                leads_ref.append(features)  # Append the feature array (1D)\n","\n","            # Combine features and append to examples\n","            if leads_ref:\n","                leads_ref = torch.tensor(np.array(leads_ref), dtype=torch.float32)  # Shape: (num_leads, num_features)\n","                label_tensor = torch.tensor([disease], dtype=torch.float32)  # Ensure label shape is (1,)\n","                examples.append((leads_ref, label_tensor))\n","\n","        except Exception as e:\n","            print(f\"Error processing sample at index {start_idx}: {e}\")\n","            continue\n","\n","    return examples\n","\n","# DataLoader Preparation Function\n","def prepare_dataloader(data, batch_size=32, shuffle=True):\n","    \"\"\"\n","    Prepare a DataLoader from formatted data.\n","    \"\"\"\n","    try:\n","        features = torch.stack([item[0] for item in data])  # Stacking feature tensors\n","        labels = torch.stack([item[1] for item in data])    # Stacking label tensors\n","        dataset = TensorDataset(features, labels)\n","        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n","\n","    except Exception as e:\n","        print(f\"Error in prepare_dataloader: {e}\")\n","        return None\n","\n","# Example Debugging\n","if __name__ == \"__main__\":\n","    # Simulate a small DataFrame with sample data\n","    import pandas as pd\n","    test_df = pd.DataFrame({\n","        'Vals': [\n","            '[0.1, 0.2, 0.3, 0, 0.0]', '[0.2, 0.4, 0.6, 0, 0.1]',  # Add realistic signal strings\n","            '[0.1, 0.2, 0.3, 0, 0.0]', '[0.2, 0.4, 0.6,0, 0.1]'\n","        ] * 18  # Simulate 12 leads per sample\n","    })\n","\n","    formatted_data = create_formatted(df_sinus[:18*5], disease=0, lead_target=0)\n","    for i, (features, label) in enumerate(formatted_data[:5]):\n","        print(f\"Sample {i}: Feature shape: {features.shape}, Label shape: {label.shape}\")\n","\n","    dataloader = prepare_dataloader(formatted_data)\n","    for batch_features, batch_labels in dataloader:\n","        print(f\"Batch features shape: {batch_features.shape}, Batch labels shape: {batch_labels.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zLQXBc3nItGn","executionInfo":{"status":"ok","timestamp":1733895441433,"user_tz":360,"elapsed":330,"user":{"displayName":"Kronos Vocos","userId":"08102118984188024326"}},"outputId":"c23bd44c-1820-4c84-f481-e392d8d59f99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 5/5 [00:00<00:00, 20.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Sample 0: Feature shape: torch.Size([1, 6]), Label shape: torch.Size([1])\n","Sample 1: Feature shape: torch.Size([1, 6]), Label shape: torch.Size([1])\n","Sample 2: Feature shape: torch.Size([1, 6]), Label shape: torch.Size([1])\n","Sample 3: Feature shape: torch.Size([1, 6]), Label shape: torch.Size([1])\n","Sample 4: Feature shape: torch.Size([1, 6]), Label shape: torch.Size([1])\n","Batch features shape: torch.Size([5, 1, 6]), Batch labels shape: torch.Size([5, 1])\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class FeatureClassifier(nn.Module):\n","    def __init__(self, input_features=6):\n","        \"\"\"\n","        Neural network for processing features and performing binary classification.\n","        Parameters:\n","        - input_features: Number of input features for each sample (default is 6).\n","        \"\"\"\n","        super(FeatureClassifier, self).__init__()\n","        self.fc1 = nn.Linear(input_features, 64)  # Fully connected layer 1\n","        self.fc2 = nn.Linear(64, 32)  # Fully connected layer 2\n","        self.fc3 = nn.Linear(32, 1)  # Output layer for binary classification\n","        self.relu = nn.ReLU()  # Activation function\n","        self.dropout = nn.Dropout(0.3)  # Dropout to prevent overfitting\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of the network.\n","        Parameters:\n","        - x: Input tensor of shape (batch_size, 1, 6)\n","\n","        Returns:\n","        - Output tensor of shape (batch_size, 1)\n","        \"\"\"\n","        x = x.squeeze(1)  # Remove the singleton dimension: (batch_size, 6)\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n"],"metadata":{"id":"6qh0K3YFN6-2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","# Initialize the model, loss function, and optimizer\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = FeatureClassifier(input_features=6).to(device)\n","criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss with Logits\n","optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n","\n","# Example training loop\n","def train_model(model, dataloader, epochs=10):\n","    model.train()\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        for batch_features, batch_labels in dataloader:\n","            # Move data to the correct device\n","            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n","            batch_labels = batch_labels.squeeze(1)  # Match output shape\n","\n","            # Forward pass\n","            optimizer.zero_grad()\n","            outputs = model(batch_features)\n","            loss = criterion(outputs.squeeze(1), batch_labels)\n","\n","            # Backward pass and optimization\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(dataloader):.4f}\")\n","\n","# Example dataloader usage\n","train_model(model, dataloader, epochs=10)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QU5OFvxsOY1I","executionInfo":{"status":"ok","timestamp":1733895554594,"user_tz":360,"elapsed":65,"user":{"displayName":"Kronos Vocos","userId":"08102118984188024326"}},"outputId":"75b59de6-9efc-4c74-e777-d94ce9aa8cc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 2158212.5000\n","Epoch 2/10, Loss: 3958796.7500\n","Epoch 3/10, Loss: 2967806.5000\n","Epoch 4/10, Loss: 2732744.7500\n","Epoch 5/10, Loss: 1801446.2500\n","Epoch 6/10, Loss: 470510.6562\n","Epoch 7/10, Loss: 0.0000\n","Epoch 8/10, Loss: 0.0000\n","Epoch 9/10, Loss: 127020.8125\n","Epoch 10/10, Loss: 101597.8594\n"]}]},{"cell_type":"code","source":["def evaluate_model(model, dataloader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_features, batch_labels in dataloader:\n","            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n","            batch_labels = batch_labels.squeeze(1)  # Match output shape\n","\n","            outputs = model(batch_features)\n","            predictions = torch.sigmoid(outputs) > 0.5  # Apply sigmoid and threshold\n","            correct += (predictions == batch_labels).sum().item()\n","            total += batch_labels.size(0)\n","\n","    accuracy = correct / total\n","    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n","    return accuracy\n","\n","# Example evaluation\n","evaluate_model(model, dataloader)  # Use a separate test dataloader\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JOvsx6DMOftG","executionInfo":{"status":"ok","timestamp":1733895569586,"user_tz":360,"elapsed":65,"user":{"displayName":"Kronos Vocos","userId":"08102118984188024326"}},"outputId":"05fb38d0-f427-426b-80ff-5b8e2da4978e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 500.00%\n"]},{"output_type":"execute_result","data":{"text/plain":["5.0"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from biosppy.signals import ecg\n","import numpy as np\n","from tqdm import tqdm\n","\n","from scipy.signal import butter, filtfilt\n","\n","def preprocess_signal(signal, fs=500):\n","    \"\"\"\n","    Preprocess ECG signal: Bandpass filter and normalization.\n","    \"\"\"\n","    # Bandpass filter: 0.5 Hz to 50 Hz\n","    def bandpass_filter(signal, lowcut, highcut, fs, order=4):\n","        nyquist = 0.5 * fs\n","        low = lowcut / nyquist\n","        high = highcut / nyquist\n","        b, a = butter(order, [low, high], btype='band')\n","        return filtfilt(b, a, signal)\n","\n","    # Apply bandpass filter\n","    filtered_signal = bandpass_filter(signal, lowcut=0.5, highcut=50, fs=fs)\n","\n","    # Normalize signal\n","    normalized_signal = (filtered_signal - np.min(filtered_signal)) / (np.max(filtered_signal) - np.min(filtered_signal))\n","\n","    return normalized_signal\n","\n","def extract_ecg_features(signal, fs=500):\n","    \"\"\"\n","    Extract ECG-specific features from the signal.\n","    Pads signals if they are too short for processing.\n","    \"\"\"\n","\n","    try:\n","        # Preprocess the signal: filter and normalize\n","        signal = preprocess_signal(signal, fs)\n","\n","        # Process the ECG signal and extract R-peaks\n","        out = ecg.ecg(signal=signal, sampling_rate=fs, show=False)\n","        r_peaks = out['rpeaks']\n","\n","        # Calculate features\n","        rr_intervals = np.diff(r_peaks) / fs\n","        heart_rate = 60 / np.mean(rr_intervals) if len(rr_intervals) > 0 else 0.0\n","        energy = np.sum(signal**2)\n","\n","        st_deviation = []\n","        for r_peak in r_peaks:\n","            st_idx = int(r_peak + 0.08 * fs)\n","            if st_idx < len(signal):\n","                st_deviation.append(signal[st_idx])\n","        st_deviation_mean = np.mean(st_deviation) if st_deviation else 0.0\n","\n","        qrs_duration = np.mean(rr_intervals) if len(rr_intervals) > 0 else 0.0\n","        t_wave_amplitude = np.max(signal) - np.min(signal)\n","\n","        features = [\n","            heart_rate,\n","            np.mean(rr_intervals) if len(rr_intervals) > 0 else 0.0,\n","            energy,\n","            st_deviation_mean,\n","            qrs_duration,\n","            t_wave_amplitude,\n","        ]\n","        return np.array(features)\n","\n","    except Exception as e:\n","        print(f\"Error extracting features: {e}\")\n","        return np.zeros(6)\n","\n","\n","# Create Formatted Data Function\n","def create_formatted(df, disease=0, lead_target=0):\n","    \"\"\"\n","    Preprocess the DataFrame to extract ECG leads and labels with medical features.\n","    \"\"\"\n","    examples = []\n","    fs = 500\n","\n","    for start_idx in tqdm(range(0, len(df), 18), desc=f\"Processing {disease} samples\"):\n","        try:\n","            leads_ref = []\n","\n","            for lead_idx in range(12):\n","                if lead_target is not None and lead_idx != lead_target:\n","                    continue\n","\n","                if start_idx + lead_idx >= len(df):\n","                    raise IndexError(f\"Missing data for lead {lead_idx} at index {start_idx}. Skipping sample.\")\n","\n","                row = df.iloc[start_idx + lead_idx]\n","                vals_str = row['Vals']\n","                lead_signal = np.array([float(x.strip()) for x in vals_str.strip('[]').split(',')])\n","                lead_signal = np.nan_to_num(lead_signal)\n","\n","                features = extract_ecg_features(lead_signal, fs=fs)\n","                #print(features)\n","                leads_ref.append(features)\n","\n","            if leads_ref:\n","                leads_ref = torch.tensor(np.array(leads_ref), dtype=torch.float32).flatten(0, -1)\n","                label_tensor = torch.tensor(disease, dtype=torch.float32)  # Ensure label is a scalar\n","                examples.append((leads_ref, label_tensor))\n","\n","        except Exception as e:\n","            print(f\"Error processing sample at index {start_idx}: {e}\")\n","            continue\n","\n","    return examples\n","\n","# DataLoader Preparation Function\n","def prepare_dataloader(data, batch_size=32, shuffle=True):\n","    \"\"\"\n","    Prepare a DataLoader from formatted data.\n","    \"\"\"\n","    try:\n","        features = torch.stack([item[0] for item in data])\n","        labels = torch.tensor([item[1] for item in data]).unsqueeze(1)  # Ensure labels are shaped correctly\n","        dataset = TensorDataset(features, labels)\n","        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n","\n","    except Exception as e:\n","        print(f\"Error in prepare_dataloader: {e}\")\n","        return None\n","# Revised Neural Network with Weight Initialization\n","class FeatureClassifier(nn.Module):\n","    def __init__(self, input_features=6):\n","        super(FeatureClassifier, self).__init__()\n","        self.fc1 = nn.Linear(input_features, 64)\n","        self.fc2 = nn.Linear(64, 32)\n","        self.fc3 = nn.Linear(32, 16)\n","        self.fc4 = nn.Linear(16, 1)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.4)  # Increase dropout for better regularization\n","\n","        # Initialize weights\n","        for layer in [self.fc1, self.fc2, self.fc3, self.fc4]:\n","            nn.init.xavier_uniform_(layer.weight)\n","            nn.init.zeros_(layer.bias)\n","\n","    def forward(self, x):\n","        x = x.squeeze(1)\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.fc2(x))\n","        x = self.relu(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","\n","\n","# Training Loop with Improvements\n","for lead_num in range(12):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = FeatureClassifier(input_features=6).to(device)\n","\n","    # Check class distribution for pos_weight\n","    normal = create_formatted(df_sinus.iloc[:18*300], 0, lead_num)\n","    arythmia = create_formatted(df_sinus_a.iloc[:18*300], 1, lead_num)\n","    train_data = normal + arythmia\n","    train_labels = [item[1].item() for item in train_data]\n","    class_counts = np.bincount(train_labels)\n","    pos_weight = torch.tensor([class_counts[0] / class_counts[1]]).to(device)\n","\n","    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)  # Add L2 regularization\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5, verbose=True)\n","\n","    print(f\"Lead {lead_num}:\")\n","    train_loader = prepare_dataloader(train_data)\n","\n","    best_loss = float('inf')\n","    patience = 15\n","    patience_counter = 0\n","\n","    for epoch in range(500):\n","        model.train()\n","        running_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","\n","            # Gradient clipping\n","            nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n","\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","            #print(outputs)\n","\n","            predictions = (torch.sigmoid(outputs) > 0.5).float()\n","            correct_train += (predictions == labels).sum().item()\n","            total_train += labels.size(0)\n","\n","        train_accuracy = correct_train / total_train\n","        scheduler.step(running_loss)\n","\n","        # Early stopping\n","        if running_loss < best_loss:\n","            best_loss = running_loss\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= patience:\n","                print(f\"Stopping early at epoch {epoch+1}\")\n","                break\n","\n","        if epoch % 25 == 0:\n","            print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy * 100:.2f}%\")\n","\n","    # Evaluate Model\n","    test_data = create_formatted(df_sinus.iloc[18*300:18*400], 0, lead_num) + create_formatted(df_sinus_a.iloc[18*300:18*400], 1, lead_num)\n","    test_loader = prepare_dataloader(test_data)\n","\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            predictions = (torch.sigmoid(outputs) > 0.5).float()\n","            correct += (predictions == labels).sum().item()\n","            total += labels.size(0)\n","\n","    accuracy = correct / total\n","    print(f\"Lead {lead_num} Test Accuracy: {accuracy * 100:.2f}%\\n\")\n","\n","    del model\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"piSyIRk2OsAM","executionInfo":{"status":"ok","timestamp":1733898099525,"user_tz":360,"elapsed":765438,"user":{"displayName":"Kronos Vocos","userId":"08102118984188024326"}},"outputId":"63a6226f-6030-447a-e3a5-e2b8f65a10c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:21<00:00, 13.76it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:22<00:00, 13.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 0:\n","Epoch 1, Loss: 11.9393, Train Accuracy: 50.83%\n","Epoch 26, Loss: 0.7520, Train Accuracy: 50.83%\n","Epoch 51, Loss: 0.6918, Train Accuracy: 54.33%\n","Epoch 76, Loss: 0.6874, Train Accuracy: 54.17%\n","Epoch 101, Loss: 0.6904, Train Accuracy: 55.33%\n","Stopping early at epoch 108\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 100/100 [00:07<00:00, 13.50it/s]\n","Processing 1 samples: 100%|██████████| 100/100 [00:07<00:00, 13.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 0 Test Accuracy: 53.00%\n","\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:22<00:00, 13.37it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:22<00:00, 13.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 1:\n","Epoch 1, Loss: 25.2071, Train Accuracy: 49.00%\n","Epoch 26, Loss: 0.8820, Train Accuracy: 48.33%\n","Epoch 51, Loss: 0.7207, Train Accuracy: 51.67%\n","Epoch 76, Loss: 0.6920, Train Accuracy: 55.67%\n","Epoch 101, Loss: 0.6923, Train Accuracy: 54.00%\n","Stopping early at epoch 115\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 100/100 [00:07<00:00, 13.78it/s]\n","Processing 1 samples: 100%|██████████| 100/100 [00:07<00:00, 13.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 1 Test Accuracy: 53.50%\n","\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:21<00:00, 14.17it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:22<00:00, 13.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 2:\n","Epoch 1, Loss: 60.4616, Train Accuracy: 53.00%\n","Epoch 26, Loss: 2.0403, Train Accuracy: 46.83%\n","Epoch 51, Loss: 0.9115, Train Accuracy: 55.33%\n","Epoch 76, Loss: 0.8553, Train Accuracy: 49.67%\n","Epoch 101, Loss: 0.7144, Train Accuracy: 51.83%\n","Epoch 126, Loss: 0.7286, Train Accuracy: 54.67%\n","Stopping early at epoch 131\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 100/100 [00:07<00:00, 13.52it/s]\n","Processing 1 samples: 100%|██████████| 100/100 [00:07<00:00, 13.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 2 Test Accuracy: 49.00%\n","\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:21<00:00, 13.66it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:22<00:00, 13.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 3:\n","Epoch 1, Loss: 85.5683, Train Accuracy: 51.67%\n","Epoch 26, Loss: 6.7684, Train Accuracy: 48.17%\n","Epoch 51, Loss: 1.3423, Train Accuracy: 50.00%\n","Epoch 76, Loss: 0.9522, Train Accuracy: 49.50%\n","Epoch 101, Loss: 0.8246, Train Accuracy: 53.33%\n","Epoch 126, Loss: 0.8129, Train Accuracy: 49.67%\n","Epoch 151, Loss: 0.7162, Train Accuracy: 55.00%\n","Stopping early at epoch 163\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 100/100 [00:07<00:00, 13.79it/s]\n","Processing 1 samples: 100%|██████████| 100/100 [00:07<00:00, 13.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 3 Test Accuracy: 50.00%\n","\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:21<00:00, 13.71it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:22<00:00, 13.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 4:\n","Epoch 1, Loss: 79.7124, Train Accuracy: 49.83%\n","Epoch 26, Loss: 1.9808, Train Accuracy: 52.33%\n","Epoch 51, Loss: 0.9453, Train Accuracy: 50.83%\n","Epoch 76, Loss: 0.7544, Train Accuracy: 51.67%\n","Stopping early at epoch 88\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 100/100 [00:07<00:00, 13.47it/s]\n","Processing 1 samples: 100%|██████████| 100/100 [00:07<00:00, 13.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 4 Test Accuracy: 51.00%\n","\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:21<00:00, 14.16it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:22<00:00, 13.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 5:\n","Epoch 1, Loss: 21.5249, Train Accuracy: 46.83%\n","Epoch 26, Loss: 1.3847, Train Accuracy: 50.17%\n","Epoch 51, Loss: 0.7932, Train Accuracy: 52.50%\n","Epoch 76, Loss: 0.7455, Train Accuracy: 55.50%\n","Epoch 101, Loss: 0.6856, Train Accuracy: 53.67%\n","Stopping early at epoch 107\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 100/100 [00:07<00:00, 13.73it/s]\n","Processing 1 samples: 100%|██████████| 100/100 [00:07<00:00, 13.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 5 Test Accuracy: 60.50%\n","\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:22<00:00, 13.57it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:21<00:00, 13.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 6:\n","Epoch 1, Loss: 74.8474, Train Accuracy: 49.17%\n","Epoch 26, Loss: 0.7147, Train Accuracy: 49.50%\n","Stopping early at epoch 36\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 100/100 [00:07<00:00, 13.82it/s]\n","Processing 1 samples: 100%|██████████| 100/100 [00:07<00:00, 13.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 6 Test Accuracy: 50.00%\n","\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:22<00:00, 13.52it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:22<00:00, 13.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 7:\n","Epoch 1, Loss: 59.5119, Train Accuracy: 52.33%\n","Epoch 26, Loss: 6.8039, Train Accuracy: 47.17%\n","Epoch 51, Loss: 1.0076, Train Accuracy: 49.67%\n","Epoch 76, Loss: 0.8355, Train Accuracy: 52.00%\n","Epoch 101, Loss: 0.7746, Train Accuracy: 53.33%\n","Stopping early at epoch 109\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 100/100 [00:07<00:00, 13.69it/s]\n","Processing 1 samples: 100%|██████████| 100/100 [00:07<00:00, 13.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 7 Test Accuracy: 50.00%\n","\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:21<00:00, 14.05it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:21<00:00, 13.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 8:\n","Epoch 1, Loss: 38.9522, Train Accuracy: 50.17%\n","Epoch 26, Loss: 1.1387, Train Accuracy: 51.67%\n","Epoch 51, Loss: 0.7540, Train Accuracy: 53.33%\n","Epoch 76, Loss: 0.7349, Train Accuracy: 56.33%\n","Stopping early at epoch 100\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 100/100 [00:07<00:00, 13.89it/s]\n","Processing 1 samples: 100%|██████████| 100/100 [00:07<00:00, 13.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 8 Test Accuracy: 59.00%\n","\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:21<00:00, 14.15it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:21<00:00, 14.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 9:\n","Epoch 1, Loss: 23.9316, Train Accuracy: 49.17%\n","Epoch 26, Loss: 0.8067, Train Accuracy: 54.17%\n","Epoch 51, Loss: 0.6824, Train Accuracy: 57.00%\n","Epoch 76, Loss: 0.6721, Train Accuracy: 57.33%\n","Stopping early at epoch 83\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 100/100 [00:07<00:00, 14.09it/s]\n","Processing 1 samples: 100%|██████████| 100/100 [00:07<00:00, 13.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 9 Test Accuracy: 65.50%\n","\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:21<00:00, 14.09it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:21<00:00, 13.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 10:\n","Epoch 1, Loss: 22.8467, Train Accuracy: 52.17%\n","Epoch 26, Loss: 0.9991, Train Accuracy: 50.33%\n","Epoch 51, Loss: 0.7152, Train Accuracy: 56.00%\n","Epoch 76, Loss: 0.6806, Train Accuracy: 59.50%\n","Epoch 101, Loss: 0.6739, Train Accuracy: 60.67%\n","Stopping early at epoch 107\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 100/100 [00:07<00:00, 13.66it/s]\n","Processing 1 samples: 100%|██████████| 100/100 [00:07<00:00, 13.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 10 Test Accuracy: 62.50%\n","\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 300/300 [00:21<00:00, 13.84it/s]\n","Processing 1 samples: 100%|██████████| 300/300 [00:22<00:00, 13.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Lead 11:\n","Epoch 1, Loss: 15.3376, Train Accuracy: 50.17%\n","Epoch 26, Loss: 1.4267, Train Accuracy: 49.83%\n","Epoch 51, Loss: 0.7791, Train Accuracy: 52.17%\n","Stopping early at epoch 67\n"]},{"output_type":"stream","name":"stderr","text":["Processing 0 samples: 100%|██████████| 100/100 [00:07<00:00, 13.63it/s]\n","Processing 1 samples: 100%|██████████| 100/100 [00:07<00:00, 13.59it/s]"]},{"output_type":"stream","name":"stdout","text":["Lead 11 Test Accuracy: 50.00%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5Mrb1y-JPXnu"},"execution_count":null,"outputs":[]}]}